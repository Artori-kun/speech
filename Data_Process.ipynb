{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import iglob, glob\n",
    "import os\n",
    "import sys\n",
    "from python_speech_features import mfcc\n",
    "import numpy as np\n",
    "import random\n",
    "import progressbar\n",
    "import librosa\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corpus location\n",
    "data_dir = '/home/minhhiu/MyProjects/Compressed Speech Data/full_command_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE_TOKEN = '<space>'\n",
    "SPACE_INDEX = 0\n",
    "FIRST_INDEX = ord('a') - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/minhhieu/My Projects/Compressed Speech Data/full_command_data/train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-1ee77d42b8f5>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# create a list of all commands\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mtrain_f\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_dir\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"train.txt\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"r\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m#delete whatever was in the file\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mcmd_list_f\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_dir\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"cmd_list.txt\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"w\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/minhhieu/My Projects/Compressed Speech Data/full_command_data/train.txt'"
     ]
    }
   ],
   "source": [
    "# create a list of all commands\n",
    "train_f = open(os.path.join(data_dir,\"train.txt\"),\"r\")\n",
    "\n",
    "#delete whatever was in the file\n",
    "cmd_list_f = open(os.path.join(data_dir,\"cmd_list.txt\"),\"w\")\n",
    "cmd_list_f.close()\n",
    "\n",
    "cmd_list_f = open(os.path.join(data_dir,\"cmd_list.txt\"),\"a\")\n",
    "\n",
    "cmd = train_f.readline()\n",
    "prev_cmd = ''\n",
    "while cmd != '':\n",
    "    if cmd != prev_cmd:\n",
    "        cmd_list_f.write(cmd)\n",
    "        prev_cmd = cmd\n",
    "    cmd = train_f.readline()\n",
    "train_f.close()\n",
    "cmd_list_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['đ', 'è', 'n', 'p', 'h', 'ò', 'g', 'k', 'á', 'c', 'b', 'ậ', 't', 'ủ', 'ắ', 'm', 'ế', 's', 'ơ', 'ố', 'i', 'ă', 'ộ', 'ả', 'ó', 'r', 'ử', 'a', 'ở', 'é', 'o', 'l', 'ê', 'x', 'u', 'y', 'ể', 'à', 'v', 'ỏ', 'í']\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "#create labels for characters\n",
    "cmd_f = open(os.path.join(data_dir,\"cmd_list.txt\"),\"r\")\n",
    "\n",
    "cmd = \" \"\n",
    "char_list = []\n",
    "\n",
    "while cmd != \"\":\n",
    "    cmd = cmd_f.readline().lower()\n",
    "    for char in cmd:\n",
    "        if char not in char_list and char != \" \" and char != \"\\n\":\n",
    "            char_list.append(char)\n",
    "print(char_list)\n",
    "print(len(char_list))\n",
    "\n",
    "cmd_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<space>': 0, 'đ': 1, 'è': 2, 'n': 3, 'p': 4, 'h': 5, 'ò': 6, 'g': 7, 'k': 8, 'á': 9, 'c': 10, 'b': 11, 'ậ': 12, 't': 13, 'ủ': 14, 'ắ': 15, 'm': 16, 'ế': 17, 's': 18, 'ơ': 19, 'ố': 20, 'i': 21, 'ă': 22, 'ộ': 23, 'ả': 24, 'ó': 25, 'r': 26, 'ử': 27, 'a': 28, 'ở': 29, 'é': 30, 'o': 31, 'l': 32, 'ê': 33, 'x': 34, 'u': 35, 'y': 36, 'ể': 37, 'à': 38, 'v': 39, 'ỏ': 40, 'í': 41, '<blank>': 42}\n",
      "{0: '<space>', 1: 'đ', 2: 'è', 3: 'n', 4: 'p', 5: 'h', 6: 'ò', 7: 'g', 8: 'k', 9: 'á', 10: 'c', 11: 'b', 12: 'ậ', 13: 't', 14: 'ủ', 15: 'ắ', 16: 'm', 17: 'ế', 18: 's', 19: 'ơ', 20: 'ố', 21: 'i', 22: 'ă', 23: 'ộ', 24: 'ả', 25: 'ó', 26: 'r', 27: 'ử', 28: 'a', 29: 'ở', 30: 'é', 31: 'o', 32: 'l', 33: 'ê', 34: 'x', 35: 'u', 36: 'y', 37: 'ể', 38: 'à', 39: 'v', 40: 'ỏ', 41: 'í', 42: '<blank>'}\n",
      "{'char_num': 42, 'encode': {'<space>': 0, 'đ': 1, 'è': 2, 'n': 3, 'p': 4, 'h': 5, 'ò': 6, 'g': 7, 'k': 8, 'á': 9, 'c': 10, 'b': 11, 'ậ': 12, 't': 13, 'ủ': 14, 'ắ': 15, 'm': 16, 'ế': 17, 's': 18, 'ơ': 19, 'ố': 20, 'i': 21, 'ă': 22, 'ộ': 23, 'ả': 24, 'ó': 25, 'r': 26, 'ử': 27, 'a': 28, 'ở': 29, 'é': 30, 'o': 31, 'l': 32, 'ê': 33, 'x': 34, 'u': 35, 'y': 36, 'ể': 37, 'à': 38, 'v': 39, 'ỏ': 40, 'í': 41, '<blank>': 42}, 'decode': {0: '<space>', 1: 'đ', 2: 'è', 3: 'n', 4: 'p', 5: 'h', 6: 'ò', 7: 'g', 8: 'k', 9: 'á', 10: 'c', 11: 'b', 12: 'ậ', 13: 't', 14: 'ủ', 15: 'ắ', 16: 'm', 17: 'ế', 18: 's', 19: 'ơ', 20: 'ố', 21: 'i', 22: 'ă', 23: 'ộ', 24: 'ả', 25: 'ó', 26: 'r', 27: 'ử', 28: 'a', 29: 'ở', 30: 'é', 31: 'o', 32: 'l', 33: 'ê', 34: 'x', 35: 'u', 36: 'y', 37: 'ể', 38: 'à', 39: 'v', 40: 'ỏ', 41: 'í', 42: '<blank>'}}\n"
     ]
    }
   ],
   "source": [
    "#character dictionary\n",
    "encode_dic = {}\n",
    "decode_dic = {}\n",
    "\n",
    "encode_dic[SPACE_TOKEN] = 0\n",
    "value = 1\n",
    "for char in char_list:\n",
    "    if not char:\n",
    "        break\n",
    "    \n",
    "    encode_dic[char] = value\n",
    "    value += 1\n",
    "\n",
    "encode_dic['<blank>'] = value\n",
    "print(encode_dic)\n",
    "\n",
    "decode_dic = {v : k for k, v in encode_dic.items()}\n",
    "# decode_dic[value] = '<blank>'\n",
    "\n",
    "print(decode_dic)\n",
    "\n",
    "label_dic = {}\n",
    "label_dic[\"char_num\"] = value\n",
    "label_dic[\"encode\"] = encode_dic\n",
    "label_dic[\"decode\"] = decode_dic\n",
    "\n",
    "print(label_dic)\n",
    "\n",
    "with open(\"encode_decode.json\", \"w\", encoding=\"utf-8\") as en_de_file:\n",
    "    json.dump(label_dic, en_de_file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_txt = 'Đèn phòng ngủ chuyển màu xanh'\n",
    "original = ' '.join(target_txt.strip().lower().split(' ')).replace('.', '').replace('?', '').replace(',', '').replace(\"'\", '').replace('!', '').replace('-', '').replace('\\t', '').replace(')', '').replace('\"', '')\n",
    "targets = original.replace(' ', '  ')\n",
    "targets = targets.split(' ')\n",
    "print(targets)\n",
    "    \n",
    "# Adding blank label\n",
    "targets = np.hstack([SPACE_TOKEN if x == '' else list(x) for x in targets])\n",
    "print(targets)\n",
    "\n",
    "# Transform char into index\n",
    "targets = np.asarray([encode_dic[x] for x in targets])\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a text file corresponding to every single records\n",
    "cmd_list_f = open(os.path.join(data_dir,\"cmd_list.txt\"), \"r\")\n",
    "\n",
    "directory = 1\n",
    "\n",
    "while directory <= 71:\n",
    "    text = cmd_list_f.readline()\n",
    "    \n",
    "    wavs = [f for f in os.listdir(os.path.join(data_dir, str(directory))) \n",
    "            if os.path.isfile(os.path.join(data_dir, str(directory), f)) \n",
    "            and f.endswith('.wav')]\n",
    "    for wav in wavs:\n",
    "        wavpath = os.path.join(data_dir, str(directory), wav)\n",
    "        wavpath = wavpath.replace('wav','txt')\n",
    "        \n",
    "        text_f = open(os.path.join(wavpath), \"w\")\n",
    "        text_f.write(text)\n",
    "        text_f.close()\n",
    "    directory = directory + 1\n",
    "cmd_list_f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(folder, partition_dict=None, seed=78):\n",
    "    \"\"\"Split VCTK data into train, dev, test sets.\n",
    "        Args:\n",
    "            folder: the folder path to the data (string)\n",
    "            partition_dict: dictionary for train/dev/test split (default 0.8/0.1/0.1)\n",
    "        Returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "    if partition_dict is None:\n",
    "        partition_dict = {'train':0.8, 'dev':0.1, 'test':0.1}\n",
    "    assert sum(partition_dict.values()) == 1\n",
    "    speaker_folders = glob(os.path.join(folder,'*'))\n",
    "    for speaker_folder in speaker_folders:\n",
    "        #print(speaker_folder)\n",
    "        wav_files = glob(os.path.join(speaker_folder, '*.wav' ))\n",
    "        #print(len(wav_files))\n",
    "        random.seed(seed)\n",
    "        random.shuffle(wav_files)\n",
    "        quantities = [(name, round(ratio*len(wav_files))) for (name, ratio) in partition_dict.items()]\n",
    "        for name, quantity in quantities:\n",
    "            #print(quantity)\n",
    "            for _ in range(quantity):\n",
    "                try:\n",
    "                    audio = wav_files.pop()\n",
    "                    new_path_wav = os.path.join(folder, name, 'wav', speaker_folder.split('/')[-1], os.path.basename(audio))\n",
    "                    os.renames(audio, new_path_wav)\n",
    "                    old_path_txt = audio.replace(\"wav\",\"txt\").replace(\"wav\",\"txt\")\n",
    "                    new_path_txt = new_path_wav.replace(\"wav\",\"txt\").replace(\"wav\",\"txt\")\n",
    "                    os.renames(old_path_txt, new_path_txt)\n",
    "                except IndexError as e:\n",
    "                    pass\n",
    "\n",
    "def find_files(directory, pattern='**/*.wav'):\n",
    "    \"\"\"Recursively finds all files matching the pattern.\"\"\"\n",
    "    return sorted(iglob(os.path.join(directory, pattern), recursive=True))\n",
    "\n",
    "def read_audio_from_filename(filename, sample_rate):\n",
    "    \"\"\"Load a wav file and transpose the array.\"\"\"\n",
    "    audio, _ = librosa.load(filename, sr=sample_rate, mono=True)\n",
    "    audio = audio.reshape(-1, 1)\n",
    "    return audio\n",
    "\n",
    "def convert_txt_index(target_txt):\n",
    "    \"\"\"Turn text into index.\"\"\"\n",
    "    original = ' '.join(target_txt.strip().lower().split(' ')).replace('.', '').replace('?', '').replace(',', '').replace(\"'\", '').replace('!', '').replace('-', '').replace('\\t', '').replace(')', '').replace('\"', '')\n",
    "    targets = original.replace(' ', '  ')\n",
    "    targets = targets.split(' ')\n",
    "    \n",
    "    # Adding blank label\n",
    "    targets = np.hstack([SPACE_TOKEN if x == '' else list(x) for x in targets])\n",
    "    # Transform char into index\n",
    "    targets = np.asarray([encode_dic[x] for x in targets])\n",
    "    return targets, original\n",
    "\n",
    "def return_txt_path(wav_path):\n",
    "    \"\"\"Return the corresponding txt location for VCTK data set.\"\"\"\n",
    "    return wav_path.replace(\"wav\",\"txt\").replace(\"wav\",\"txt\")\n",
    "\n",
    "def find_speaker_ID(wav_path):\n",
    "    \"\"\"Find speaker ID from the path of a wav file.\"\"\"\n",
    "    return (wav_path.split('.')[0].split('/')[-1] + '_' +\n",
    "            wav_path.split('.')[0].split('/')[-2])\n",
    "\n",
    "def pack_data_npz(DIR, input_mfcc, target, speaker_wav_ID, original):\n",
    "    \"\"\"Pickle data into npz files.\"\"\"\n",
    "    np.savez(os.path.join(DIR, speaker_wav_ID),\\\n",
    "             data_in=input_mfcc, target=target, seq_len=np.array([len(input_mfcc)]), original=np.array([original]))\n",
    "\n",
    "def convert_wav_mfcc(file, fs):\n",
    "    \"\"\"Turn raw audio data into MFCC with sample rate=fs.\"\"\"\n",
    "    inputs = mfcc(read_audio_from_filename(file, fs),samplerate=16000,winlen=0.025,winstep=0.01,numcep=39,\n",
    "                 nfilt=40)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split VCTK data into trian/test/dev set\n",
    "data_split(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -7.11787461  -3.80257675  -5.1892211   -6.10649606 -14.93026671\n",
      "  -6.50852211 -11.0820522  -11.38528159  -5.4359234  -11.92452621\n",
      "  -7.35473919  -8.55734981 -13.01601318  -3.9352292   -8.98238838\n",
      "  -4.68796679  -1.95915871  -1.73154274  -2.08739357  -0.03456929\n",
      "  -0.53198038   0.01748119  -0.11119716   0.09039443   0.353582\n",
      "  -0.09068641   0.32179263  -0.5481161   -0.26260662  -0.2551881\n",
      "  -0.05354107   0.36378776   0.36751137  -0.67487943   0.03250879\n",
      "  -0.79729677  -0.62674145  -0.34291148  -0.49919057]\n",
      "[4.80709436e+01 2.73225564e+02 2.56144587e+02 2.82365340e+02\n",
      " 3.64473904e+02 3.50754526e+02 2.94261552e+02 2.77978943e+02\n",
      " 2.59434337e+02 2.72846929e+02 2.23980478e+02 2.38807094e+02\n",
      " 2.40063544e+02 1.45434149e+02 1.30000553e+02 8.78272953e+01\n",
      " 7.08331217e+01 4.77805934e+01 2.90516462e+01 1.77374929e+01\n",
      " 9.81691185e+00 3.53698520e+00 4.37489065e-01 1.28564162e-01\n",
      " 1.73595741e+00 4.84757899e+00 8.52678182e+00 1.32094524e+01\n",
      " 1.59793449e+01 1.90119549e+01 2.20582108e+01 2.35460995e+01\n",
      " 2.37752211e+01 2.21998490e+01 2.13201087e+01 2.06950096e+01\n",
      " 1.84171366e+01 1.50563522e+01 1.09329295e+01]\n",
      "[ 6.93332126 16.5295361  16.00451772 16.80372993 19.09119966 18.72844163\n",
      " 17.15405352 16.67270054 16.10696547 16.51807885 14.96597736 15.45338454\n",
      " 15.49398411 12.05960815 11.40177852  9.37162181  8.41624154  6.91235079\n",
      "  5.3899579   4.2115903   3.13319515  1.88068743  0.66142956  0.35855845\n",
      "  1.31755737  2.20172182  2.92006538  3.63448103  3.99741728  4.36027005\n",
      "  4.69661695  4.85243233  4.87598411  4.71167157  4.61737032  4.54917681\n",
      "  4.29151915  3.88025157  3.30649807]\n"
     ]
    }
   ],
   "source": [
    "#find mean, and varience of training data for normalization\n",
    "directory = data_dir + '/train/wav'\n",
    "\n",
    "bar = progressbar.ProgressBar()\n",
    "n =0\n",
    "sum_mfcc = np.zeros(39) \n",
    "sumsq_mfcc = np.zeros(39)\n",
    "total_len = 0\n",
    "for file in bar(find_files(directory, pattern='**/*.wav')): \n",
    "    audio = mfcc(read_audio_from_filename(file, 16000),samplerate=16000,winlen=0.025,winstep=0.01,numcep=39,\n",
    "                 nfilt=40)\n",
    "\n",
    "    sum_mfcc += np.sum(audio, axis = 0)\n",
    "    sumsq_mfcc +=np.sum(audio*audio, axis = 0)\n",
    "    total_len += len(audio)\n",
    "    n += 1\n",
    "\n",
    "m = sum_mfcc/total_len\n",
    "v = sumsq_mfcc/(total_len-1) - m*m\n",
    "s = np.sqrt(v)\n",
    "\n",
    "print(m)\n",
    "print(v)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490133\n"
     ]
    }
   ],
   "source": [
    "print(total_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_DIR = data_dir + '/MFCC_39_16khz/train/'\n",
    "directory = data_dir + '/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\r\n"
     ]
    }
   ],
   "source": [
    "# Pickle Training data\n",
    "\n",
    "if not os.path.exists(Train_DIR):\n",
    "    os.makedirs(Train_DIR)\n",
    "    \n",
    "bar = progressbar.ProgressBar()\n",
    "for wav_path in bar(find_files(directory, pattern='**/*.wav')):\n",
    "    #print(wav_path)\n",
    "    speaker_ID = find_speaker_ID(wav_path)\n",
    "    #print(speaker_ID)\n",
    "    txt_path = return_txt_path(wav_path)\n",
    "    target, original = convert_txt_index(open(txt_path).read().strip())\n",
    "    inputs = convert_wav_mfcc(wav_path, 16000)\n",
    "    normalize_inputs = (inputs - m)/s\n",
    "    pack_data_npz(Train_DIR, normalize_inputs, target, speaker_ID, original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\r\n"
     ]
    }
   ],
   "source": [
    "# Pickle Dev data\n",
    "\n",
    "DIR = data_dir + '/MFCC_39_16khz/dev/'\n",
    "directory = data_dir + '/val/'\n",
    "\n",
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)\n",
    "    \n",
    "bar = progressbar.ProgressBar()\n",
    "for wav_path in bar(find_files(directory, pattern='**/*.wav')):\n",
    "    #print(wav_path)\n",
    "    speaker_ID = find_speaker_ID(wav_path)\n",
    "    #print(speaker_ID)\n",
    "    txt_path = return_txt_path(wav_path)\n",
    "    target, original = convert_txt_index(open(txt_path).read().strip())\n",
    "    inputs = convert_wav_mfcc(wav_path, 16000)\n",
    "    normalize_inputs = (inputs - m)/s\n",
    "    pack_data_npz(DIR, normalize_inputs, target, speaker_ID, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\r\n"
     ]
    }
   ],
   "source": [
    "# Pickle Test data\n",
    "\n",
    "DIR = data_dir + '/MFCC_39_16khz/test/'\n",
    "directory = data_dir + '/test/'\n",
    "\n",
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)\n",
    "    \n",
    "bar = progressbar.ProgressBar()\n",
    "for wav_path in bar(find_files(directory, pattern='**/*.wav')):\n",
    "    #print(wav_path)\n",
    "    speaker_ID = find_speaker_ID(wav_path)\n",
    "    #print(speaker_ID)\n",
    "    txt_path = return_txt_path(wav_path)\n",
    "    target, original = convert_txt_index(open(txt_path).read().strip())\n",
    "    inputs = convert_wav_mfcc(wav_path, 16000)\n",
    "    \n",
    "    normalize_inputs = (inputs - m)/s\n",
    "    pack_data_npz(DIR, normalize_inputs, target, speaker_ID, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f7561efbf8608b6e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f7561efbf8608b6e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir '/home/minhhiu/MyProjects/speech/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.53987793 -1.269448    1.67310601 ... -2.27360753 -0.4295214\n",
      "  -3.69245003]\n",
      " [-9.8267141  -1.28899542  1.87876153 ... -0.34186347 -0.09316157\n",
      "  -4.08470592]\n",
      " [-9.8248009  -3.34290005 -0.75952223 ... -0.49052357 -0.16833934\n",
      "   0.20581648]\n",
      " ...\n",
      " [-8.57498707 -7.17791755 10.58529722 ...  0.12683245  6.34203963\n",
      "  -0.48419089]\n",
      " [-8.53691756 -6.65650265 15.18826144 ... -1.8499269   1.57116769\n",
      "  -2.23493946]\n",
      " [-8.19465177 -7.62449687  5.21408897 ... -3.14172332  0.31766861\n",
      "  -3.21747218]]\n"
     ]
    }
   ],
   "source": [
    "DIR = data_dir + '/MFCC_39_16khz/test/rec_8_1.npz'\n",
    "data = np.load(DIR)\n",
    "print(data['data_in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}