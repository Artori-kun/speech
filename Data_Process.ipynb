{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import iglob, glob\n",
    "import os\n",
    "import sys\n",
    "from python_speech_features import mfcc\n",
    "import numpy as np\n",
    "import random\n",
    "import progressbar\n",
    "import librosa\n",
    "\n",
    "def data_split(folder, partition_dict=None, seed=78):\n",
    "    \"\"\"Split VCTK data into train, dev, test sets.\n",
    "        Args:\n",
    "            folder: the folder path to the data (string)\n",
    "            partition_dict: dictionary for train/dev/test split (default 0.8/0.1/0.1)\n",
    "        Returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "    if partition_dict is None:\n",
    "        partition_dict = {'train':0.8, 'dev':0.1, 'test':0.1}\n",
    "    assert sum(partition_dict.values()) == 1\n",
    "    speaker_folders = glob(os.path.join(folder,'*'))\n",
    "    for speaker_folder in speaker_folders:\n",
    "        #print(speaker_folder)\n",
    "        wav_files = glob(os.path.join(speaker_folder, '*.wav' ))\n",
    "        #print(len(wav_files))\n",
    "        random.seed(seed)\n",
    "        random.shuffle(wav_files)\n",
    "        quantities = [(name, round(ratio*len(wav_files))) for (name, ratio) in partition_dict.items()]\n",
    "        for name, quantity in quantities:\n",
    "            #print(quantity)\n",
    "            for _ in range(quantity):\n",
    "                try:\n",
    "                    audio = wav_files.pop()\n",
    "                    new_path_wav = os.path.join(folder, name, 'wav', speaker_folder.split('/')[-1], os.path.basename(audio))\n",
    "                    os.renames(audio, new_path_wav)\n",
    "                    old_path_txt = audio.replace(\"wav\",\"txt\").replace(\"wav\",\"txt\")\n",
    "                    new_path_txt = new_path_wav.replace(\"wav\",\"txt\").replace(\"wav\",\"txt\")\n",
    "                    os.renames(old_path_txt, new_path_txt)\n",
    "                except IndexError as e:\n",
    "                    pass\n",
    "\n",
    "def find_files(directory, pattern='**/*.wav'):\n",
    "    \"\"\"Recursively finds all files matching the pattern.\"\"\"\n",
    "    return sorted(iglob(os.path.join(directory, pattern), recursive=True))\n",
    "\n",
    "def read_audio_from_filename(filename, sample_rate):\n",
    "    \"\"\"Load a wav file and transpose the array.\"\"\"\n",
    "    audio, _ = librosa.load(filename, sr=sample_rate, mono=True)\n",
    "    audio = audio.reshape(-1, 1)\n",
    "    return audio\n",
    "\n",
    "def convert_txt_index(target_txt):\n",
    "    \"\"\"Turn text into index.\"\"\"\n",
    "    original = ' '.join(target_txt.strip().lower().split(' ')).replace('.', '').replace('?', '').replace(',', '').replace(\"'\", '').replace('!', '').replace('-', '').replace('\\t', '').replace(')', '').replace('\"', '')\n",
    "    targets = original.replace(' ', '  ')\n",
    "    targets = targets.split(' ')\n",
    "    \n",
    "    # Adding blank label\n",
    "    targets = np.hstack([SPACE_TOKEN if x == '' else list(x) for x in targets])\n",
    "    # Transform char into index\n",
    "    targets = np.asarray([SPACE_INDEX if x == SPACE_TOKEN else ord(x) - FIRST_INDEX\n",
    "                          for x in targets])\n",
    "    return targets, original\n",
    "\n",
    "def return_txt_path(wav_path):\n",
    "    \"\"\"Return the corresponding txt location for VCTK data set.\"\"\"\n",
    "    return wav_path.replace(\"wav\",\"txt\").replace(\"wav\",\"txt\")\n",
    "\n",
    "def find_speaker_ID(wav_path):\n",
    "    \"\"\"Find speaker ID from the path of a wav file.\"\"\"\n",
    "    return wav_path.split('.')[0].split('/')[-1]\n",
    "\n",
    "def pack_data_npz(DIR, input_mfcc, target, speaker_wav_ID, original):\n",
    "    \"\"\"Pickle data into npz files.\"\"\"\n",
    "    np.savez(os.path.join(DIR, speaker_wav_ID),\\\n",
    "             data_in=input_mfcc, target=target, seq_len=np.array([len(input_mfcc)]), original=np.array([original]))\n",
    "\n",
    "def convert_wav_mfcc(file, fs):\n",
    "    \"\"\"Turn raw audio data into MFCC with sample rate=fs.\"\"\"\n",
    "    inputs = mfcc(read_audio_from_filename(file, fs),samplerate=16000,winlen=0.025,winstep=0.01,numcep=39,\n",
    "                 nfilt=40)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corpus location\n",
    "data_dir = '/home/minhhieu/My Projects/Compressed Speech Data/command_aHieu/data_cmds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1207\n"
     ]
    }
   ],
   "source": [
    "train_f = open(os.path.join(data_dir,\"train.txt\"),\"r\")\n",
    "counter = 0\n",
    "content = train_f.read()\n",
    "colist = content.split(\"\\n\")\n",
    "for i in colist:\n",
    "    if i:\n",
    "        counter += 1\n",
    "\n",
    "print(counter)\n",
    "train_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all commands\n",
    "train_f = open(os.path.join(data_dir,\"train.txt\"),\"r\")\n",
    "\n",
    "#delete whatever was in the file\n",
    "cmd_list_f = open(os.path.join(data_dir,\"cmd_list.txt\"),\"w\")\n",
    "cmd_list_f.close()\n",
    "\n",
    "cmd_list_f = open(os.path.join(data_dir,\"cmd_list.txt\"),\"a\")\n",
    "\n",
    "cmd = train_f.readline()\n",
    "prev_cmd = ''\n",
    "while cmd != '':\n",
    "    if cmd != prev_cmd:\n",
    "        cmd_list_f.write(cmd)\n",
    "        prev_cmd = cmd\n",
    "    cmd = train_f.readline()\n",
    "train_f.close()\n",
    "cmd_list_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a text file corresponding to every single records\n",
    "cmd_list_f = open(os.path.join(data_dir,\"cmd_list.txt\"), \"r\")\n",
    "\n",
    "directory = 0\n",
    "\n",
    "while directory <= 70:\n",
    "    text = cmd_list_f.readline()\n",
    "    \n",
    "    wavs = [f for f in os.listdir(os.path.join(data_dir, str(directory))) \n",
    "            if os.path.isfile(os.path.join(data_dir, str(directory), f)) \n",
    "            and f.endswith('.wav')]\n",
    "    for wav in wavs:\n",
    "        wavpath = os.path.join(data_dir, str(directory), wav)\n",
    "        wavpath = wavpath.replace('wav','txt')\n",
    "        \n",
    "        text_f = open(os.path.join(wavpath), \"w\")\n",
    "        text_f.write(text)\n",
    "        text_f.close()\n",
    "    directory = directory + 1\n",
    "cmd_list_f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split VCTK data into trian/test/dev set\n",
    "data_split(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -4.7142037    2.67463059  -6.26692545  -0.86938414 -17.76231234\n",
      "  -5.00257211  -5.39799636 -16.52314351  -2.42566297 -15.41543841\n",
      "  -6.1217356  -11.66405996 -15.78104423  -5.33257431  -7.94131976\n",
      "  -2.43818405  -2.55286844  -0.92384073  -2.74482856  -0.65408305\n",
      "  -1.35580234  -0.29269695  -0.23433919   0.12245257   0.50280009\n",
      "  -0.39649036   0.81109185  -1.29818507   0.08517973  -0.58516622\n",
      "   0.53700888   0.02567575   0.4447999   -0.70513672  -0.12575338\n",
      "  -1.02424198  -0.78371256  -0.70379923  -0.52070044]\n",
      "[8.43151570e+00 2.69039695e+02 3.08331083e+02 3.05043797e+02\n",
      " 6.88538956e+02 3.97221865e+02 3.63112248e+02 3.24360884e+02\n",
      " 3.15167410e+02 3.57302126e+02 2.48696067e+02 2.90939072e+02\n",
      " 2.78930546e+02 1.83713492e+02 1.36820044e+02 8.69230245e+01\n",
      " 7.86322820e+01 5.17433923e+01 2.86640510e+01 1.86508130e+01\n",
      " 9.42721648e+00 3.33434792e+00 4.73556895e-01 1.29365346e-01\n",
      " 1.68558517e+00 4.46272142e+00 7.74387472e+00 1.21501602e+01\n",
      " 1.76504581e+01 1.96237808e+01 2.24384471e+01 2.27667003e+01\n",
      " 2.49632254e+01 2.59909792e+01 2.53655562e+01 2.45752192e+01\n",
      " 2.22732147e+01 1.83792415e+01 1.28191465e+01]\n",
      "[ 2.90370723 16.40242955 17.55935883 17.46550307 26.24002584 19.93042562\n",
      " 19.05550439 18.01002177 17.75295498 18.90243704 15.7701004  17.05693617\n",
      " 16.70121391 13.55409502 11.69701004  9.32325182  8.86748454  7.193288\n",
      "  5.35388186  4.3186587   3.07037725  1.82601969  0.6881547   0.35967394\n",
      "  1.29830088  2.11251542  2.78278183  3.48570799  4.20124483  4.42987368\n",
      "  4.7369238   4.77144635  4.99632119  5.09813488  5.03642295  4.95733993\n",
      "  4.71945068  4.28710176  3.58038357]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#find mean, and varience of training data for normalization\n",
    "directory = '/home/minhhieu/My Projects/Compressed Speech Data/command_aHieu/data_cmds/train/wav'\n",
    "\n",
    "bar = progressbar.ProgressBar()\n",
    "n =0\n",
    "sum_mfcc = np.zeros(39) \n",
    "sumsq_mfcc = np.zeros(39)\n",
    "total_len = 0\n",
    "for file in bar(find_files(directory, pattern='**/*.wav')): \n",
    "    audio = mfcc(read_audio_from_filename(file, 16000),samplerate=16000,winlen=0.025,winstep=0.01,numcep=39,\n",
    "                 nfilt=40)\n",
    "\n",
    "    sum_mfcc += np.sum(audio, axis = 0)\n",
    "    sumsq_mfcc +=np.sum(audio*audio, axis = 0)\n",
    "    total_len += len(audio)\n",
    "    n += 1\n",
    "\n",
    "m = sum_mfcc/total_len\n",
    "v = sumsq_mfcc/(total_len-1) - m*m\n",
    "s = np.sqrt(v)\n",
    "\n",
    "print(m)\n",
    "print(v)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158963\n"
     ]
    }
   ],
   "source": [
    "print(total_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE_TOKEN = '<space>'\n",
    "SPACE_INDEX = 0\n",
    "FIRST_INDEX = ord('a') - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_DIR = '/home/minhhieu/My Projects/Compressed Speech Data/command_aHieu/MFCC_39_16khz/train/'\n",
    "directory = '/home/minhhieu/My Projects/Compressed Speech Data/command_aHieu/data_cmds/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "# Pickle Training data\n",
    "\n",
    "if not os.path.exists(Train_DIR):\n",
    "    os.makedirs(Train_DIR)\n",
    "    \n",
    "bar = progressbar.ProgressBar()\n",
    "for wav_path in bar(find_files(directory, pattern='**/*.wav')):\n",
    "    #print(wav_path)\n",
    "    speaker_ID = find_speaker_ID(wav_path)\n",
    "    #print(speaker_ID)\n",
    "    txt_path = return_txt_path(wav_path)\n",
    "    target, original = convert_txt_index(open(txt_path).read().strip())\n",
    "    inputs = convert_wav_mfcc(wav_path, 16000)\n",
    "    normalize_inputs = (inputs - m)/s\n",
    "    pack_data_npz(Train_DIR, normalize_inputs, target, speaker_ID, original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "# Pickle Dev data\n",
    "\n",
    "DIR = '/home/minhhieu/My Projects/Compressed Speech Data/command_aHieu/MFCC_39_16khz/dev/'\n",
    "directory = '/home/minhhieu/My Projects/Compressed Speech Data/command_aHieu/data_cmds/dev/'\n",
    "\n",
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)\n",
    "    \n",
    "bar = progressbar.ProgressBar()\n",
    "for wav_path in bar(find_files(directory, pattern='**/*.wav')):\n",
    "    #print(wav_path)\n",
    "    speaker_ID = find_speaker_ID(wav_path)\n",
    "    #print(speaker_ID)\n",
    "    txt_path = return_txt_path(wav_path)\n",
    "    target, original = convert_txt_index(open(txt_path).read().strip())\n",
    "    inputs = convert_wav_mfcc(wav_path, 16000)\n",
    "    normalize_inputs = (inputs - m)/s\n",
    "    pack_data_npz(DIR, normalize_inputs, target, speaker_ID, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "# Pickle Test data\n",
    "\n",
    "DIR = '/home/minhhieu/My Projects/Compressed Speech Data/command_aHieu/MFCC_39_16khz/test/'\n",
    "directory = '/home/minhhieu/My Projects/Compressed Speech Data/command_aHieu/data_cmds/test/'\n",
    "\n",
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)\n",
    "    \n",
    "bar = progressbar.ProgressBar()\n",
    "for wav_path in bar(find_files(directory, pattern='**/*.wav')):\n",
    "    #print(wav_path)\n",
    "    speaker_ID = find_speaker_ID(wav_path)\n",
    "    #print(speaker_ID)\n",
    "    txt_path = return_txt_path(wav_path)\n",
    "    target, original = convert_txt_index(open(txt_path).read().strip())\n",
    "    inputs = convert_wav_mfcc(wav_path, 16000)\n",
    "    normalize_inputs = (inputs - m)/s\n",
    "    pack_data_npz(DIR, normalize_inputs, target, speaker_ID, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
